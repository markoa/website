---
title: "AI-Generated Personal Message Equals Trash"
description: "A personal message that feels AI-generated is dismissed at best, and considered offensive at worst."
pubDate: 2025-06-03 9:48Z
type: "article"
published: true
---

[A paper from Harvard Business School (PDF)](https://www.hbs.edu/ris/Publication%20Files/25-008_7583ddd3-d5ed-46d5-9475-453a44da0f60.pdf) provides data evidence on something we all knew: people dismiss AI-generated personal messages at best, and consider them offensive at worst.

People could barely tell AI from human messages (59% accuracy), but when they _thought_ something was AI-generated, they rated it as less helpful even when a human actually wrote it.

What's also interesting is that the harder the AI tried to sound human, the stronger people's aversion became when they detected it.

I believe that most managers will eventually have an AI avatar that people can talk to when they're not around. But using AI to generate a message to send to someone else is a different matter.

There's plenty of ways to leverage AI for communication and decision making. Use AI to brainstorm counter-arguments, detect blind spots, research background, or polish your draft - but the ideas and final message must be yours. You must stand 100% behind them.

People don't just read your words. The basic currency between humans is trust. So even when they're not consciously thinking about it, every time you talk to someone they're deciding whether to trust you.

Use AI to think better, not to think for you. Because the moment you stop owning your words, you stop being worth listening to.
